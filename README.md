# pre-training_cook

## Uncategorized
- [JetMoe](https://github.com/myshell-ai/JetMoE)


## Scaling Law
- [MiniCPM](https://github.com/OpenBMB/MiniCPM/tree/main), [MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](https://arxiv.org/abs/2404.06395)
- [Compression Represents Intelligence Linearly](https://arxiv.org/pdf/2404.09937.pdf)

## Data
- [Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/pdf/2404.02078.pdf): sft, preference tuning

## Reasoning: weaker-to-stronger, sel-tuning, self-learning
- [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/pdf/2403.09629.pdf)
- [STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning](https://arxiv.org/pdf/2403.09629.pdf)
